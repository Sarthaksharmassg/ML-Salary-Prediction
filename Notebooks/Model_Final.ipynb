{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d39317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT MODULES\n",
    "#IMPORT MODULES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "# SENTIMENT ANALYSIS USING VADER\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "646ce203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE DATA FILE\n",
    "df1 = pd.read_csv(\"../Datasets/survey_results_public.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2bff7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD COLUMNS HERE\n",
    "\n",
    "#Employment Column Additions\n",
    "column_name = \"Employment\"\n",
    "st = set()\n",
    "for i in range (0,len(df1)):\n",
    "    value = str(df1[column_name].iloc[i])\n",
    "    if(value == \"nan\"):continue\n",
    "    l = value.split(\";\")\n",
    "    for ele in l:\n",
    "        st.add(ele)\n",
    "for ele in st:\n",
    "    df1[ele] = 0\n",
    "    \n",
    "for i in range (0,len(df1)):\n",
    "    value = str(df1[column_name].iloc[i])\n",
    "    if(value == \"nan\"):continue\n",
    "    l = value.split(\";\")\n",
    "    for ele in l:\n",
    "        df1.loc[i,ele] = 1\n",
    "\n",
    "#Countries filtered out if not India\n",
    "df1 = df1[df1[\"Industry\"] == \"Information Services, IT, Software Development, or other Technology\"]\n",
    "#Industries filtered out if not Information Services, IT, Software Development, or other Technology\n",
    "df1 = df1[df1[\"Country\"] == \"India\"]\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"LanguageHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfLanguagesKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "# Number of Databases known\n",
    "column_name = \"DatabaseHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfDatabasesKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"PlatformHaveWorkedWith\"\n",
    "def platformcount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfPlatformsKnown\"] = df1.apply(platformcount,axis = 1)\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"WebframeHaveWorkedWith\"\n",
    "def webframecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfWebframesKnown\"] = df1.apply(webframecount,axis = 1)\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"MiscTechHaveWorkedWith\"\n",
    "def misctechcount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfMiscTechsKnown\"] = df1.apply(misctechcount,axis = 1)\n",
    "\n",
    "#Number of Operating Systems familiar with\n",
    "column_name = \"OpSysPersonal use\"\n",
    "def opsyscount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfOpSys\"] = df1.apply(opsyscount,axis = 1)\n",
    "\n",
    "#Number of Sources from which Coding was learnt\n",
    "column_name = \"LearnCode\"\n",
    "def learncodecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfLearningSources\"] = df1.apply(learncodecount,axis = 1)\n",
    "\n",
    "# df1 = df1[df1[\"Currency\"] == \"INR\\tIndian rupee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4590a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_selected =  [\n",
    "   'Age',\n",
    "   'AISelect',\n",
    "   'OrgSize',\n",
    "   'DevType',\n",
    "   'YearsCode',\n",
    "   'WorkExp', \n",
    "   'YearsCodePro',\n",
    "   \"RemoteWork\",\n",
    "   'Currency',\n",
    "   \"EdLevel\",\n",
    "   \"ConvertedCompYearly\",\n",
    "   \"NumberOfDatabasesKnown\",\n",
    "   \"NumberOfLanguagesKnown\",\n",
    "   # \"NumberOfPlatformsKnown\",\n",
    "   # \"NumberOfWebframesKnown\",\n",
    "   # \"NumberOfMiscTechsKnown\",\n",
    "   # \"NumberOfOpSys\",\n",
    "   \"NumberOfLearningSources\"\n",
    "]\n",
    "\n",
    "train_columns = [\n",
    "   'Age',\n",
    "   'AISelect',\n",
    "   'OrgSize',\n",
    "   'DevType',\n",
    "   \"RemoteWork\",\n",
    "   'Currency',\n",
    "   \"EdLevel\",\n",
    "   \"ExperienceCategory\",\n",
    "   \"YearsCodeCategory\",\n",
    "   \"YearsCodeProCategory\",\n",
    "   \"NumberOfDatabasesKnown\",\n",
    "   \"NumberOfLanguagesKnown\",\n",
    "   # \"NumberOfPlatformsKnown\",\n",
    "   # \"NumberOfWebframesKnown\",\n",
    "   # \"NumberOfMiscTechsKnown\",\n",
    "   # \"NumberOfOpSys\",\n",
    "   \"NumberOfLearningSources\"\n",
    "]\n",
    "\n",
    "df1 = df1[columns_selected]\n",
    "\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a47c069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE COLUMNS  INTO MAJORITY VALUES AND 'OTHER'\n",
    "def shorten_categories(categories, cutoff):\n",
    "    categorical_map = {}\n",
    "    for i in range(len(categories)):\n",
    "        if categories.values[i] >= cutoff:\n",
    "            categorical_map[categories.index[i]] = categories.index[i]\n",
    "        else:\n",
    "            categorical_map[categories.index[i]] = 'Other'\n",
    "    return categorical_map\n",
    "\n",
    "\n",
    "currency_map = shorten_categories(df1.Currency.value_counts(), 400)\n",
    "df1['Currency'] = df1['Currency'].map(currency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b4a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE THE WORK EXPERIENCE INTO BINS\n",
    "bins = [0, 2, 5, 10, 20, 30, 40, 50, float('inf')]  # Define custom bin edges\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7]  # Define labels\n",
    "\n",
    "# Create a new column with the categories\n",
    "df1['ExperienceCategory'] = pd.cut(df1['WorkExp'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd9eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE LESS THAN 1 YEAR AS 0 AND MORE THAN 50 AS 51 FOR YEARS OF CODE\n",
    "df1['YearsCode'] = df1['YearsCode'].replace(\"Less than 1 year\", 0)\n",
    "df1['YearsCode'] = df1['YearsCode'].replace(\"More than 50 years\", 51)\n",
    "\n",
    "df1['YearsCodePro'] = df1['YearsCodePro'].replace(\"Less than 1 year\", 0)\n",
    "df1['YearsCodePro'] = df1['YearsCodePro'].replace(\"More than 50 years\", 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef025523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE YEARS OF CODE INTO BINS\n",
    "bins = [0, 2, 5, 10, 20, 30, 40, 50, float('inf')]  # Define custom bin edges\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7]  # Define labels\n",
    "\n",
    "# Create a new column with the categories\n",
    "df1[\"YearsCode\"] = df1[\"YearsCode\"].astype(int)\n",
    "df1[\"YearsCodePro\"] = df1[\"YearsCodePro\"].astype(int)\n",
    "df1['YearsCodeCategory'] = pd.cut(df1['YearsCode'], bins=bins, labels=labels)\n",
    "df1['YearsCodeProCategory'] = pd.cut(df1['YearsCodePro'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de0c7fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6448c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n"
     ]
    }
   ],
   "source": [
    "#LABEL ENCODE THE COLUMNS\n",
    "\n",
    "df_LE = df1\n",
    "df_LE = df_LE.dropna()\n",
    "\n",
    "for i in train_columns:\n",
    "    if i == \"ConvertedCompYearly\":\n",
    "        continue\n",
    "    le = LabelEncoder()\n",
    "    df_LE[i] = le.fit_transform(df_LE[i])\n",
    "\n",
    "X = df_LE[train_columns]\n",
    "\n",
    "Y = df_LE[\"ConvertedCompYearly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "780b713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4497bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=1.0),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"XGBoost\" : XGBRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"Neural Network\": MLPRegressor(),\n",
    "    \"Gaussian Process\": GaussianProcessRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2979d57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EdLevel', 0.028415714801725302),\n",
       " ('Currency', 0.028740333278275368),\n",
       " ('Age', 0.038454629808528845),\n",
       " ('RemoteWork', 0.041367588324230514),\n",
       " ('YearsCodeProCategory', 0.053735950159042443),\n",
       " ('AISelect', 0.05917113583112263),\n",
       " ('NumberOfLearningSources', 0.07266669090910043),\n",
       " ('YearsCodeCategory', 0.07303334133461918),\n",
       " ('NumberOfDatabasesKnown', 0.08245576740277982),\n",
       " ('OrgSize', 0.0870377676820867),\n",
       " ('DevType', 0.11475042014260495),\n",
       " ('ExperienceCategory', 0.14253874008837022),\n",
       " ('NumberOfLanguagesKnown', 0.17763192023751365)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK IMPORTANCE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, Y)\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "map_ = {}\n",
    "\n",
    "for i, a in enumerate(X):\n",
    "    map_[a] = feature_importances[i]\n",
    "    \n",
    "sorted(map_.items(), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71153b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_18492\\201078824.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_models = pd.concat([df_models, pd.DataFrame([row])], ignore_index=True)\n",
      "c:\\Users\\Siddharth Shah\\anaconda3\\envs\\eightfoldai\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Run Time (minutes)           MAE           MSE  \\\n",
      "2                    Lasso                0.00   9358.227263  1.580163e+08   \n",
      "0        Linear Regression                0.00   9357.984769  1.580255e+08   \n",
      "1                    Ridge                0.00   9359.929522  1.580290e+08   \n",
      "6        Gradient Boosting                0.00  10734.998613  2.097617e+08   \n",
      "4            Random Forest                0.01  11089.367229  2.390293e+08   \n",
      "7   Support Vector Machine                0.00  12751.953567  2.677026e+08   \n",
      "10        Gaussian Process                0.00  13490.502422  3.842854e+08   \n",
      "8      K-Nearest Neighbors                0.00  13362.301205  3.938724e+08   \n",
      "5                  XGBoost                0.00  15356.273448  6.573327e+08   \n",
      "9           Neural Network                0.01  19887.855050  6.578297e+08   \n",
      "3            Decision Tree                0.00  15932.734940  6.996392e+08   \n",
      "\n",
      "            RMSE        R2  \n",
      "2   12570.453953  0.409733  \n",
      "0   12570.817783  0.409699  \n",
      "1   12570.957300  0.409686  \n",
      "6   14483.152259  0.216439  \n",
      "4   15460.573902  0.107111  \n",
      "7   16361.620423  0.000002  \n",
      "10  19603.197526 -0.435490  \n",
      "8   19846.218281 -0.471302  \n",
      "5   25638.500578 -1.455453  \n",
      "9   25648.190657 -1.457309  \n",
      "3   26450.694398 -1.613488  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddharth Shah\\anaconda3\\envs\\eightfoldai\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "columns = ['Model', 'Run Time (minutes)', 'MAE', 'MSE', 'RMSE', 'R2']\n",
    "df_models = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Loop through your regression models\n",
    "for key, clf in classifiers.items():\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test_scaled)\n",
    "    # CALCULATE REGRESSION METRICS\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)  # Calculate RMSE\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    row = {'Model': key,\n",
    "           'Run Time (minutes)': round((time.time() - start_time) / 60, 2),\n",
    "           'MAE': mae,\n",
    "           'MSE': mse,\n",
    "           'RMSE': rmse,\n",
    "           'R2': r2\n",
    "           }\n",
    "\n",
    "    df_models = pd.concat([df_models, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by R-squared (R2) in descending order\n",
    "df_models = df_models.sort_values(by='R2', ascending=False)\n",
    "\n",
    "# PRINT THE MODELS WITH REGRESSION METRICS [SORTED]\n",
    "print(df_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
