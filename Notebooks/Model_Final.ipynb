{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1d39317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT MODULES\n",
    "#IMPORT MODULES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "# SENTIMENT ANALYSIS USING VADER\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "646ce203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE DATA FILE\n",
    "df1 = pd.read_csv(\"../Datasets/survey_results_public.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c2bff7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD COLUMNS HERE\n",
    "\n",
    "#Employment Column Additions\n",
    "column_name = \"Employment\"\n",
    "st = set()\n",
    "for i in range (0,len(df1)):\n",
    "    value = str(df1[column_name].iloc[i])\n",
    "    if(value == \"nan\"):continue\n",
    "    l = value.split(\";\")\n",
    "    for ele in l:\n",
    "        st.add(ele)\n",
    "for ele in st:\n",
    "    df1[ele] = 0\n",
    "    \n",
    "for i in range (0,len(df1)):\n",
    "    value = str(df1[column_name].iloc[i])\n",
    "    if(value == \"nan\"):continue\n",
    "    l = value.split(\";\")\n",
    "    for ele in l:\n",
    "        df1.loc[i,ele] = 1\n",
    "\n",
    "#Countries filtered out if not India\n",
    "df1 = df1[df1[\"Industry\"] == \"Information Services, IT, Software Development, or other Technology\"]\n",
    "#Industries filtered out if not Information Services, IT, Software Development, or other Technology\n",
    "df1 = df1[df1[\"Country\"] == \"India\"]\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"LanguageHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfLanguagesKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "# Number of Databases known\n",
    "column_name = \"DatabaseHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfDatabasesKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"PlatformHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfPlatformsKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"WebframeHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfWebframesKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "#Number of Languages known\n",
    "column_name = \"MiscTechHaveWorkedWith\"\n",
    "def languagecount(row):\n",
    "    value = str(row[column_name]).split(\";\")\n",
    "    if(value[0] == \"nan\"):return 0\n",
    "    return len(value)\n",
    "df1[\"NumberOfMiscTechsKnown\"] = df1.apply(languagecount,axis = 1)\n",
    "\n",
    "# df1 = df1[df1[\"Currency\"] == \"INR\\tIndian rupee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4590a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_selected =  [\n",
    "   'Age',\n",
    "   'AISelect',\n",
    "   'OrgSize',\n",
    "   'DevType',\n",
    "   'YearsCode',\n",
    "   'WorkExp', \n",
    "   'YearsCodePro',\n",
    "   \"RemoteWork\",\n",
    "   'Currency',\n",
    "   \"EdLevel\",\n",
    "   \"ConvertedCompYearly\",\n",
    "   \"NumberOfDatabasesKnown\",\n",
    "   \"NumberOfLanguagesKnown\",\n",
    "   # \"NumberOfPlatformsKnown\",\n",
    "   # \"NumberOfWebframesKnown\",\n",
    "   # \"NumberOfMiscTechsKnown\"\n",
    "]\n",
    "\n",
    "train_columns = [\n",
    "   'Age',\n",
    "   'AISelect',\n",
    "   'OrgSize',\n",
    "   'DevType',\n",
    "   \"RemoteWork\",\n",
    "   'Currency',\n",
    "   \"EdLevel\",\n",
    "   \"ExperienceCategory\",\n",
    "   \"YearsCodeCategory\",\n",
    "   \"YearsCodeProCategory\",\n",
    "   \"NumberOfDatabasesKnown\",\n",
    "   \"NumberOfLanguagesKnown\",\n",
    "   # \"NumberOfPlatformsKnown\",\n",
    "   # \"NumberOfWebframesKnown\",\n",
    "   # \"NumberOfMiscTechsKnown\"\n",
    "]\n",
    "\n",
    "df1 = df1[columns_selected]\n",
    "\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a47c069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE COLUMNS  INTO MAJORITY VALUES AND 'OTHER'\n",
    "def shorten_categories(categories, cutoff):\n",
    "    categorical_map = {}\n",
    "    for i in range(len(categories)):\n",
    "        if categories.values[i] >= cutoff:\n",
    "            categorical_map[categories.index[i]] = categories.index[i]\n",
    "        else:\n",
    "            categorical_map[categories.index[i]] = 'Other'\n",
    "    return categorical_map\n",
    "\n",
    "\n",
    "currency_map = shorten_categories(df1.Currency.value_counts(), 400)\n",
    "df1['Currency'] = df1['Currency'].map(currency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c1b4a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE THE WORK EXPERIENCE INTO BINS\n",
    "bins = [0, 2, 5, 10, 20, 30, 40, 50, float('inf')]  # Define custom bin edges\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7]  # Define labels\n",
    "\n",
    "# Create a new column with the categories\n",
    "df1['ExperienceCategory'] = pd.cut(df1['WorkExp'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "1cd9eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE LESS THAN 1 YEAR AS 0 AND MORE THAN 50 AS 51 FOR YEARS OF CODE\n",
    "df1['YearsCode'] = df1['YearsCode'].replace(\"Less than 1 year\", 0)\n",
    "df1['YearsCode'] = df1['YearsCode'].replace(\"More than 50 years\", 51)\n",
    "\n",
    "df1['YearsCodePro'] = df1['YearsCodePro'].replace(\"Less than 1 year\", 0)\n",
    "df1['YearsCodePro'] = df1['YearsCodePro'].replace(\"More than 50 years\", 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ef025523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISE YEARS OF CODE INTO BINS\n",
    "bins = [0, 2, 5, 10, 20, 30, 40, 50, float('inf')]  # Define custom bin edges\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7]  # Define labels\n",
    "\n",
    "# Create a new column with the categories\n",
    "df1[\"YearsCode\"] = df1[\"YearsCode\"].astype(int)\n",
    "df1[\"YearsCodePro\"] = df1[\"YearsCodePro\"].astype(int)\n",
    "df1['YearsCodeCategory'] = pd.cut(df1['YearsCode'], bins=bins, labels=labels)\n",
    "df1['YearsCodeProCategory'] = pd.cut(df1['YearsCodePro'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "de0c7fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "e6448c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n",
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\2931493265.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LE[i] = le.fit_transform(df_LE[i])\n"
     ]
    }
   ],
   "source": [
    "#LABEL ENCODE THE COLUMNS\n",
    "\n",
    "df_LE = df1\n",
    "df_LE = df_LE.dropna()\n",
    "\n",
    "for i in train_columns:\n",
    "    if i == \"ConvertedCompYearly\":\n",
    "        continue\n",
    "    le = LabelEncoder()\n",
    "    df_LE[i] = le.fit_transform(df_LE[i])\n",
    "\n",
    "X = df_LE[train_columns]\n",
    "\n",
    "Y = df_LE[\"ConvertedCompYearly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "780b713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4497bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=1.0),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"XGBoost\" : XGBRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"Neural Network\": MLPRegressor(),\n",
    "    \"Gaussian Process\": GaussianProcessRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2979d57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Currency', 0.02817022275554761),\n",
       " ('Age', 0.034125834524362915),\n",
       " ('EdLevel', 0.03450337475680589),\n",
       " ('RemoteWork', 0.044024153706216554),\n",
       " ('YearsCodeProCategory', 0.04945189475900289),\n",
       " ('AISelect', 0.059129672030337005),\n",
       " ('YearsCodeCategory', 0.07923579689392862),\n",
       " ('OrgSize', 0.10306376089525605),\n",
       " ('NumberOfDatabasesKnown', 0.11569895375478245),\n",
       " ('DevType', 0.13536457317978143),\n",
       " ('ExperienceCategory', 0.1447316093197097),\n",
       " ('NumberOfLanguagesKnown', 0.1725001534242689)]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK IMPORTANCE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, Y)\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "map_ = {}\n",
    "\n",
    "for i, a in enumerate(X):\n",
    "    map_[a] = feature_importances[i]\n",
    "    \n",
    "sorted(map_.items(), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "71153b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth Shah\\AppData\\Local\\Temp\\ipykernel_16984\\201078824.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_models = pd.concat([df_models, pd.DataFrame([row])], ignore_index=True)\n",
      "c:\\Users\\Siddharth Shah\\anaconda3\\envs\\eightfoldai\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Run Time (minutes)           MAE           MSE  \\\n",
      "2                    Lasso                0.00   9347.035386  1.580481e+08   \n",
      "0        Linear Regression                0.00   9346.703727  1.580575e+08   \n",
      "1                    Ridge                0.00   9348.700260  1.580609e+08   \n",
      "4            Random Forest                0.01  10605.659277  2.063169e+08   \n",
      "6        Gradient Boosting                0.00  10416.370176  2.108388e+08   \n",
      "7   Support Vector Machine                0.00  12749.426441  2.676308e+08   \n",
      "5                  XGBoost                0.00  14575.203549  3.478964e+08   \n",
      "10        Gaussian Process                0.00  14655.119469  3.993367e+08   \n",
      "8      K-Nearest Neighbors                0.00  13663.320482  4.376988e+08   \n",
      "3            Decision Tree                0.00  14803.801205  5.370660e+08   \n",
      "9           Neural Network                0.01  19900.612707  6.594876e+08   \n",
      "\n",
      "            RMSE        R2  \n",
      "2   12571.719663  0.409614  \n",
      "0   12572.091945  0.409579  \n",
      "1   12572.226385  0.409567  \n",
      "4   14363.735923  0.229307  \n",
      "6   14520.288074  0.212416  \n",
      "7   16359.424600  0.000271  \n",
      "5   18651.981477 -0.299560  \n",
      "10  19983.411824 -0.491714  \n",
      "8   20921.251607 -0.635015  \n",
      "3   23174.685481 -1.006199  \n",
      "9   25680.491204 -1.463503  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddharth Shah\\anaconda3\\envs\\eightfoldai\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "columns = ['Model', 'Run Time (minutes)', 'MAE', 'MSE', 'RMSE', 'R2']\n",
    "df_models = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Loop through your regression models\n",
    "for key, clf in classifiers.items():\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test_scaled)\n",
    "    # CALCULATE REGRESSION METRICS\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)  # Calculate RMSE\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    row = {'Model': key,\n",
    "           'Run Time (minutes)': round((time.time() - start_time) / 60, 2),\n",
    "           'MAE': mae,\n",
    "           'MSE': mse,\n",
    "           'RMSE': rmse,\n",
    "           'R2': r2\n",
    "           }\n",
    "\n",
    "    df_models = pd.concat([df_models, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by R-squared (R2) in descending order\n",
    "df_models = df_models.sort_values(by='R2', ascending=False)\n",
    "\n",
    "# PRINT THE MODELS WITH REGRESSION METRICS [SORTED]\n",
    "print(df_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
